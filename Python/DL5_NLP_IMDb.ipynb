{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL5_NLP_IMDb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDE5lq2TMPsW"
      },
      "source": [
        "# 자연어 처리(NLP) : IMDb 영화 리뷰 감성 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqa3-CRRKYHq"
      },
      "source": [
        "# 라이브러리 설정\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import random\r\n",
        "\r\n",
        "# 랜덤 시드 고정\r\n",
        "SEED=12\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkCYtYgYMbUY"
      },
      "source": [
        "* 순서가 있는 시쿼스 데이터 분석에 사용되는 RNN(Recurrent Neural Network) 계열의 순환 신경망"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1qhr8UQMmjg"
      },
      "source": [
        "# IMDb 영화 리뷰 데이터 셋\r\n",
        "\r\n",
        "from tensorflow.keras import datasets\r\n",
        "imdb=datasets.imdb\r\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=10000,index_from=3)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VZ5T2DVGTkm"
      },
      "source": [
        "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pab9uu8G28J"
      },
      "source": [
        "# 첫 번째 리뷰 - 벡터\r\n",
        "print(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW1TC3bSHGeA"
      },
      "source": [
        "* 각 숫자는 실제로는 단어를 나타낸다. 자연어를 딥러닝 모델에 입력하기 위해 각 단어를 숫자와 1:1 매핑하여 숫자 인덱스로 인코딩 변환했기 때문이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqEYz5a6HNk5"
      },
      "source": [
        "# 첫 번째 리뷰 - 벡터 길이(원소 개수)\r\n",
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJfB2v8VHUD0"
      },
      "source": [
        "* 218개의 단어로 이루어진 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RycNGSjbHcqz"
      },
      "source": [
        "word_index=imdb.get_word_index()\r\n",
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UACOTmw2HoCF"
      },
      "source": [
        "# 숫자 벡터를 텍스트로 변환 ( 원래 문장으로 복원할 수 있다. )\r\n",
        "def decode_review_vector(review_vector):\r\n",
        "  index_to_word={value:key for key, value in word_index.items()}\r\n",
        "  decode_review=' '.join([index_to_word.get(idx-3,'?') for idx in review_vector])\r\n",
        "  return decode_review\r\n",
        "\r\n",
        "# 첫 번째 리뷰 디코딩\r\n",
        "decode_review_vector(x_train[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbSrVCoBIt2_"
      },
      "source": [
        "# 첫 번째 리뷰의 정답 레이블\r\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAm24y1JAg4"
      },
      "source": [
        "# 각 리뷰의 단어 개수 분포\r\n",
        "\r\n",
        "review_length=[len(review) for review in x_train]\r\n",
        "sns.displot(review_length);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teSZMr-xJW5z"
      },
      "source": [
        "# 제로 패딩\r\n",
        "\r\n",
        "1.   리뷰 데이터의 길이가 모두 다르다.\r\n",
        "2.   딥러닝 모델에 입력하기 위해 입력 데이터의 크기를 동일하게 조정해야한다.\r\n",
        "\r\n",
        "> 제로 패딩(zero padding) : 입력의 최대 길이를 설정하고, 이보다 길이가 긴 경우에는 중간에 잘라서 길이를 맞추고, 짧은 경우에는 부족한 만큼 숫자 0 으로 채운다.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOEFAy1nJ7mr"
      },
      "source": [
        "# Padding\r\n",
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "x_train_pad=sequence.pad_sequences(x_train,maxlen=250)\r\n",
        "x_test_pad=sequence.pad_sequences(x_test,maxlen=250)\r\n",
        "\r\n",
        "print(x_train_pad[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gew31cB1KT9N"
      },
      "source": [
        "# 단어 임배딩\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   IMDb 데이터를 불러올 때 num_words에 사용할 단어 개수를 10,000개로 설정했기 때문에 각 리뷰는 10,000개의 단어 사전(BoW,Back of Words)에 들어 있는 단어로 표현되어 있다. \r\n",
        "\r\n",
        "*   단어 사전에 등록된 10,000개 단어를 기준으로 원핫 인코딩을 적용하여 원핫 벡터로 변환하면 딥러닝 모델의 입력 데이터로 사용할 수 있다.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   이 경우, 모델에 충분한 정보를 전달하기 어려워지고, 단어사이의 유사성 등 언어적 특징을 모델이 학습할 수 없다.\r\n",
        "*   따라서, 단어 임베딩 활용\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhRWJDtcLHEM"
      },
      "source": [
        "# 모델 정의\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense,Dropout\r\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM,GRU\r\n",
        "\r\n",
        "def build_model(model_type='RNN'):\r\n",
        "  model=Sequential()\r\n",
        "\r\n",
        "  # Embedding\r\n",
        "  model.add(Embedding(input_dim=10000,output_dim=128))\r\n",
        "\r\n",
        "  # RNN\r\n",
        "  if model_type=='RNN':\r\n",
        "    model.add(SimpleRNN(units=64,return_sequences=True))\r\n",
        "    model.add(SimpleRNN(units=64))\r\n",
        "\r\n",
        "  # LSTM\r\n",
        "\r\n",
        "  elif model_type=='LSTM':\r\n",
        "    model.add(LSTM(units=64,return_sequences=True))\r\n",
        "    model.add(LSTM(units=64))\r\n",
        "\r\n",
        "  # GRU\r\n",
        "\r\n",
        "  elif model_type=='GRU':\r\n",
        "    model.add(GRU(units=64,return_sequences=True))\r\n",
        "    model.add(GRU(units=64))\r\n",
        "\r\n",
        "  # Dense Classifier\r\n",
        "\r\n",
        "  model.add(Dense(units=32,activation='relu'))\r\n",
        "  model.add(Dropout(rate=0.5))\r\n",
        "  model.add(Dense(units=1,activation='sigmoid'))\r\n",
        "\r\n",
        "  # Compile\r\n",
        "  model.compile(optimizer='adam',\r\n",
        "                loss='binary_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "  \r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyuN9zswXgvp"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmLawVasXiYi"
      },
      "source": [
        "rnn_model=build_model('RNN')\r\n",
        "rnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUhCRl39YdBm"
      },
      "source": [
        "rnn_history=rnn_model.fit(x_train_pad,y_train,batch_size=32,epochs=10,\r\n",
        "                          validation_split=0.1,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpgk54VrYzOj"
      },
      "source": [
        "# 20 epoch까지 손실 함수와 정확도를 그래프로 나타내는 함수\r\n",
        "\r\n",
        "def plot_metrics(history,start=1,end=20):\r\n",
        "  flt,axes=plt.subplots(1,2,figsize=(10,5))\r\n",
        "\r\n",
        "  # Loss 손실 함수\r\n",
        "  axes[0].plot(range(start,end+1),history.history['loss'][start-1:end],\r\n",
        "               label='Train')\r\n",
        "  axes[0].plot(range(start,end+1),history.history['val_loss'][start-1:end],\r\n",
        "               label='Validation')\r\n",
        "  axes[0].set_title('Loss')\r\n",
        "  axes[0].legend()\r\n",
        "\r\n",
        "  # Accuracy : 예측 정확도\r\n",
        "  axes[1].plot(range(start,end+1),history.history['accuracy'][start-1:end],\r\n",
        "               label='Train')\r\n",
        "  axes[1].plot(range(start,end+1),history.history['val_accuracy'][start-1:end],\r\n",
        "               label='Validation')\r\n",
        "  axes[1].set_title('Accuracy')\r\n",
        "  axes[1].legend()\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "# 그래프 그리기\r\n",
        "plot_metrics(history=rnn_history,start=1,end=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aq6_gDhoMaY"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yHZAbx9pFQr"
      },
      "source": [
        "\r\n",
        "\r\n",
        "1.   RNN의 단점을 보완한 모델\r\n",
        "* RNN :최근에 학습한 단어가 모델의 최종예측에 더 큰 영향을 주게된다. RNN 모델이 단기 의존성이 높다.\r\n",
        "* LSTM : 기존 정보 중에서 중요한 정보를 다음 단계에 전달하는 구조를 도입, 장기 기억 성능을 개선했다. 길이가 긴 시퀀스 데이터를 학습하는데 적합하다.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suPxq3LnpQJh"
      },
      "source": [
        "# LSTM 모델 적용\r\n",
        "lstm_model=build_model('LSTM')\r\n",
        "lstm_history=lstm_model.fit(x_train_pad,y_train,batch_size=32,epochs=10,\r\n",
        "                            validation_split=0.1,verbose=0)\r\n",
        "\r\n",
        "plot_metrics(history=lstm_history,start=1,end=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuUKNgXdqJwv"
      },
      "source": [
        "# GRU \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   LSTM의 느린 학습 속도를 개선하기 위해 제안된 알고리즘\r\n",
        "*   LSTM은 입력 시퀀스의 길이가 길어지면, 학습해야하는 가중치 파라미터의 개수가 기하급수적으로 늘기 때문에, 학습속도가 느리다는 단점이 있다.\r\n",
        "\r\n",
        "* GRU는 셀을 단순한 구조로 변경하여 파라미터 개수를 줄이고 학습 속도를 개선한 모델이다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ4Aiab2qLAU"
      },
      "source": [
        "# GRU 모델 적용\r\n",
        "\r\n",
        "gru_model=build_model('GRU')\r\n",
        "gru_model.compile(optimizer='adam',\r\n",
        "                  loss='binary_crossentropy',\r\n",
        "                  metrics=['accuracy'])\r\n",
        "\r\n",
        "gru_history=gru_model.fit(x_train_pad,y_train,batch_size=32,epochs=10,\r\n",
        "                          validation_split=0.1,verbose=0)\r\n",
        "\r\n",
        "plot_metrics(history=gru_history,start=1,end=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}